{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cseadmin/dz/TrafficFlowModel/model/deprecated'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "# sys.path.append(\"..\")\n",
    "# from lib.metrics import evaluate\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "DATA_PATH=\"../data/sz_taxi_202006/\"\n",
    "vec_size=512\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute '_unpickle_timestamp' on <module 'pandas._libs.tslibs.timestamps' from '/home/cseadmin/dz/anaconda3/envs/torch1.7/lib/python3.7/site-packages/pandas/_libs/tslibs/timestamps.cpython-37m-x86_64-linux-gnu.so'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33050/3163543450.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraj_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../data/sz_taxi_202006/sz_taxi_202006_traj_list.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtraj_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1.7/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 440\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1.7/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0mpickle_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;31m# Friendlier error message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute '_unpickle_timestamp' on <module 'pandas._libs.tslibs.timestamps' from '/home/cseadmin/dz/anaconda3/envs/torch1.7/lib/python3.7/site-packages/pandas/_libs/tslibs/timestamps.cpython-37m-x86_64-linux-gnu.so'>"
     ]
    }
   ],
   "source": [
    "traj_list=np.load(\"../../data/sz_taxi_202006/sz_taxi_202006_traj_list.npy\", allow_pickle=True)\n",
    "\n",
    "len(traj_list)\n",
    "traj_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.82609e+05, 3.98275e+05, 2.63966e+05, 1.95140e+05, 1.35211e+05,\n",
       "        9.08700e+04, 6.93990e+04, 3.69020e+04, 2.44290e+04, 1.67950e+04,\n",
       "        1.13810e+04, 7.73800e+03, 6.29200e+03, 3.59500e+03, 2.53400e+03,\n",
       "        1.90000e+03, 1.25200e+03, 9.19000e+02, 7.99000e+02, 4.25000e+02,\n",
       "        3.01000e+02, 2.22000e+02, 1.82000e+02, 1.20000e+02, 9.10000e+01,\n",
       "        8.50000e+01, 4.40000e+01, 3.30000e+01, 2.40000e+01, 1.90000e+01,\n",
       "        1.00000e+01, 1.30000e+01, 6.00000e+00, 6.00000e+00, 4.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 3.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        2.00000e+00, 0.00000e+00, 2.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00]),\n",
       " array([  1.  ,   6.16,  11.32,  16.48,  21.64,  26.8 ,  31.96,  37.12,\n",
       "         42.28,  47.44,  52.6 ,  57.76,  62.92,  68.08,  73.24,  78.4 ,\n",
       "         83.56,  88.72,  93.88,  99.04, 104.2 , 109.36, 114.52, 119.68,\n",
       "        124.84, 130.  , 135.16, 140.32, 145.48, 150.64, 155.8 , 160.96,\n",
       "        166.12, 171.28, 176.44, 181.6 , 186.76, 191.92, 197.08, 202.24,\n",
       "        207.4 , 212.56, 217.72, 222.88, 228.04, 233.2 , 238.36, 243.52,\n",
       "        248.68, 253.84, 259.  ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=5\n",
    "len_list=[]\n",
    "count=0\n",
    "for traj in traj_list:\n",
    "    len_list.append(len(traj))\n",
    "    \n",
    "len_list=np.array(len_list)\n",
    "plt.hist(len_list, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1751602"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[198, 199, 448]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tracks=[]\n",
    "for traj in traj_list:\n",
    "    road_ids=[]\n",
    "    for point in traj:\n",
    "        road_ids.append(point[0])\n",
    "    all_tracks.append(road_ids)\n",
    "\n",
    "len(all_tracks)\n",
    "all_tracks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_all_traj=Word2Vec(all_tracks, sg=1, hs=1, vector_size=vec_size, window=10, min_count=1, workers=4)\n",
    "\n",
    "w2v_all_traj.save(os.path.join(DATA_PATH, f\"w2v_all_traj_{vec_size}.model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7991076111793518"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_all_traj=Word2Vec.load(os.path.join(DATA_PATH, f\"w2v_all_traj_{vec_size}.model\"))\n",
    "wv=w2v_all_traj.wv\n",
    "\n",
    "wv.distance(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04961416,  0.03711881,  0.00701622, -0.02471929,  0.04195437,\n",
       "        0.05551275, -0.0024164 ,  0.03509161, -0.01095492,  0.05997162],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=np.argsort(wv.index_to_key)\n",
    "embed_vectors=wv.get_normed_vectors()\n",
    "\n",
    "embed_vectors=embed_vectors[index]\n",
    "embed_vectors[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 492)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1.0000002 , 0.13911077, 0.18122032, 0.20089237, 0.2514562 ,\n",
       "       0.16970405, 0.21216552, 0.12217825, 0.12732378, 0.13965628],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = embed_vectors @ embed_vectors.T\n",
    "\n",
    "correlation_matrix.shape\n",
    "correlation_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    "import math\n",
    "\n",
    "class GraphConvolution(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \n",
    "    out = A*X*W\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        print(\"inp-\", input.shape)\n",
    "        support = torch.matmul(input, self.weight) # (bs, N, hidden_dim)\n",
    "        print(\"sup-\", support.shape)\n",
    "        support=support.permute(1, 2, 0)\n",
    "        print(\"sup-\", support.shape)\n",
    "        output = torch.matmul(adj, support).permute(2, 0, 1)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "class DontKnowWhat2EatNN(torch.nn.Module):\n",
    "    def __init__(self, graph_embed_vectors, in_step, out_step, num_heads=8, drop_rate=0):\n",
    "        super(DontKnowWhat2EatNN, self).__init__()\n",
    "        \n",
    "        self.graph_embed_vectors=torch.FloatTensor(graph_embed_vectors.reshape(graph_embed_vectors.shape[0], 1, graph_embed_vectors.shape[1]))\n",
    "        self.embed_dim=graph_embed_vectors.shape[-1]\n",
    "        self.num_heads=num_heads\n",
    "        self.drop_rate=drop_rate\n",
    "        \n",
    "        self.mh_attention=torch.nn.MultiheadAttention(self.embed_dim, self.num_heads, dropout=self.drop_rate)\n",
    "        self.gcn1=GraphConvolution(in_step, 64)\n",
    "        self.bn1=torch.nn.BatchNorm2d(64)\n",
    "        self.gcn2=GraphConvolution(64, 64)\n",
    "        self.bn2=torch.nn.BatchNorm2d(64)\n",
    "        self.fc=torch.nn.Linear(64, out_step)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, N, in_step, num_features)\n",
    "        \"\"\"\n",
    "        \n",
    "        attn_output, attn_output_weights=self.mh_attention.forward(self.graph_embed_vectors, self.graph_embed_vectors, self.graph_embed_vectors)\n",
    "        attn_output=attn_output.reshape(attn_output.shape[0], attn_output.shape[2])\n",
    "        correlation_matrix=attn_output @ attn_output.T\n",
    "        \n",
    "        print(\"x-\", x.shape)\n",
    "        out=self.gcn1(x, correlation_matrix)\n",
    "        out=self.bn1(out)\n",
    "        out=self.gcn2(out, correlation_matrix)\n",
    "        out=self.bn2(out)\n",
    "        # out=out.reshape(out.shape[0], out.shape[1], -1)\n",
    "        out=self.fc(out)\n",
    "        \n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.],\n",
       "         [ 3.,  4.]],\n",
       "\n",
       "        [[ 5.,  6.],\n",
       "         [ 7.,  8.]],\n",
       "\n",
       "        [[ 9., 10.],\n",
       "         [11., 12.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000],\n",
       "        [0.5000, 0.5000]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.Tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]])\n",
    "b=torch.Tensor([[0.5, 0.5], [0.5, 0.5]])\n",
    "\n",
    "a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5000,  1.5000],\n",
       "         [ 3.5000,  3.5000]],\n",
       "\n",
       "        [[ 5.5000,  5.5000],\n",
       "         [ 7.5000,  7.5000]],\n",
       "\n",
       "        [[ 9.5000,  9.5000],\n",
       "         [11.5000, 11.5000]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  5.,  9.],\n",
       "         [ 2.,  6., 10.]],\n",
       "\n",
       "        [[ 3.,  7., 11.],\n",
       "         [ 4.,  8., 12.]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5000,  1.5000],\n",
       "         [ 3.5000,  3.5000]],\n",
       "\n",
       "        [[ 5.5000,  5.5000],\n",
       "         [ 7.5000,  7.5000]],\n",
       "\n",
       "        [[ 9.5000,  9.5000],\n",
       "         [11.5000, 11.5000]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(a, b)\n",
    "torch.matmul(b, a.permute(1, 2, 0)).permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_xy(data, in_steps, out_steps):\n",
    "    \"\"\"\n",
    "    Parameter\n",
    "    ---\n",
    "    data: (N, timesteps)\n",
    "    \n",
    "    Returns\n",
    "    ---\n",
    "    x: (num_samples, N, in_steps, num_features=1) Tensor\n",
    "    y: (num_samples, N, out_steps, num_features=1) Tensor\n",
    "        num_samples is determined by `timesteps` and `in_steps+out_steps`\n",
    "    \"\"\"\n",
    "    # Generate the beginning index and the ending index of a sample, which\n",
    "    # contains (num_points_for_training + num_points_for_predicting) points\n",
    "    all_steps=data.shape[1]\n",
    "    indices = [(i, i + (in_steps + out_steps)) for i in range(all_steps - (in_steps + out_steps) + 1)]\n",
    "    \n",
    "    x, y=[], []\n",
    "    for begin, end in indices:\n",
    "        x.append(data[:, begin: begin+in_steps])\n",
    "        y.append(data[:, begin+in_steps: end])\n",
    "        \n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    # if x.ndim==3 and y.ndim==3:\n",
    "    #     x=x[:, :, :, np.newaxis]\n",
    "    #     y=y[:, :, :, np.newaxis]\n",
    "        \n",
    "    return torch.Tensor(x), torch.Tensor(y)\n",
    "\n",
    "def read_data(data_path, file_type=\"pickle\", transpose=False):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    ---\n",
    "    X: (N, all_timesteps) numpy\n",
    "    \"\"\"\n",
    "    if file_type==\"pickle\":\n",
    "        data=pd.read_pickle(data_path)\n",
    "    elif file_type==\"csv\":\n",
    "        data=pd.read_csv(data_path)\n",
    "    else:\n",
    "        print(\"Invalid file type.\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    data=data.values.astype(np.float)\n",
    "    if transpose:\n",
    "        data=data.T\n",
    "    print(\"Original data shape\", data.shape)\n",
    "    return data\n",
    "\n",
    "def get_dataloaders(data, in_steps, out_steps, train_size=0.7, val_size=0.1, batch_size=32):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ---\n",
    "    data: (N, all_timesteps) numpy\n",
    "    \"\"\"\n",
    "    all_steps=data.shape[1]\n",
    "    split1=int(all_steps*train_size)\n",
    "    split2=int(all_steps*(train_size+val_size))\n",
    "    \n",
    "    train_data=data[:, :split1]\n",
    "    val_data=data[:, split1:split2]\n",
    "    test_data=data[:, split2:]\n",
    "    \n",
    "    x_train, y_train=gen_xy(train_data, in_steps, out_steps)\n",
    "    x_val, y_val=gen_xy(val_data, in_steps, out_steps)\n",
    "    x_test, y_test=gen_xy(test_data, in_steps, out_steps)\n",
    "    \n",
    "    print(f\"Trainset:\\tx-{x_train.size()}\\ty-{y_train.size()}\")\n",
    "    print(f\"Valset:  \\tx-{x_val.size()}  \\ty-{y_val.size()}\")\n",
    "    print(f\"Testset:\\tx-{x_test.size()}\\ty-{y_test.size()}\")\n",
    "    \n",
    "    trainset=torch.utils.data.TensorDataset(x_train, y_train)\n",
    "    valset=torch.utils.data.TensorDataset(x_val, y_val)\n",
    "    testset=torch.utils.data.TensorDataset(x_test, y_test)\n",
    "    \n",
    "    trainset_loader=torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    valset_loader=torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)\n",
    "    testset_loader=torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return trainset_loader, valset_loader, testset_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, trainset_loader, optimizer, criterion, gpu=True):\n",
    "    model.train()\n",
    "    batch_loss_list=[]\n",
    "    for x_batch, y_batch in trainset_loader:\n",
    "        if gpu and torch.cuda.is_available():\n",
    "            x_batch = x_batch.cuda()\n",
    "            y_batch = y_batch.cuda()\n",
    "\n",
    "        out_batch = model.forward(x_batch)\n",
    "        loss = criterion.forward(out_batch, y_batch)\n",
    "        batch_loss_list.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return sum(batch_loss_list)/len(batch_loss_list)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model, valset_loader, criterion, gpu=True):\n",
    "    model.eval()\n",
    "    batch_loss_list=[]\n",
    "    for x_batch, y_batch in valset_loader:\n",
    "        if gpu and torch.cuda.is_available():\n",
    "            x_batch = x_batch.cuda()\n",
    "            y_batch = y_batch.cuda()\n",
    "\n",
    "        out_batch = model.forward(x_batch)\n",
    "        loss = criterion.forward(out_batch, y_batch)\n",
    "        batch_loss_list.append(loss.item())\n",
    "\n",
    "    return sum(batch_loss_list)/len(batch_loss_list)\n",
    "\n",
    "def train(model, trainset_loader, valset_loader, optimizer, criterion, max_epochs=100, early_stop=10, verbose=1, gpu=True, plot=False):\n",
    "    wait=0\n",
    "    min_val_loss=np.inf\n",
    "    \n",
    "    train_loss_list=[]\n",
    "    val_loss_list=[]\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        train_loss=train_one_epoch(model, trainset_loader, optimizer, criterion, gpu)\n",
    "        train_loss_list.append(train_loss)\n",
    "        \n",
    "        val_loss=eval_model(model, valset_loader, criterion)\n",
    "        val_loss_list.append(val_loss)\n",
    "        \n",
    "        if (epoch+1)%verbose==0:\n",
    "            print(datetime.datetime.now(), \"Epoch\", epoch,\n",
    "                  \"\\tTrain Loss = %.5f\"%train_loss,\n",
    "                  \"\\tVal Loss = %.5f\"%val_loss)\n",
    "        \n",
    "        if val_loss<min_val_loss:\n",
    "            wait=0\n",
    "            min_val_loss=val_loss\n",
    "            best_epoch=epoch\n",
    "        else:\n",
    "            wait+=1\n",
    "            if wait >= early_stop:\n",
    "                print(\"Early stopping at epoch: %d\" % epoch)\n",
    "                break\n",
    "        \n",
    "    if plot:\n",
    "        plt.plot(range(0, epoch+1), train_loss_list, \"-\", label=\"Train Loss\")\n",
    "        plt.plot(range(0, epoch+1), val_loss_list, \"-\", label=\"Val Loss\")\n",
    "        plt.title(\"Epoch-Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape (492, 8064)\n",
      "Trainset:\tx-torch.Size([5621, 492, 12])\ty-torch.Size([5621, 492, 12])\n",
      "Valset:  \tx-torch.Size([784, 492, 12])  \ty-torch.Size([784, 492, 12])\n",
      "Testset:\tx-torch.Size([1590, 492, 12])\ty-torch.Size([1590, 492, 12])\n",
      "x- torch.Size([32, 492, 12])\n",
      "inp- torch.Size([32, 492, 12])\n",
      "sup- torch.Size([32, 492, 64])\n",
      "sup- torch.Size([492, 64, 32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (15744x64 and 492x492)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_54830/998663780.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_54830/4156769339.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainset_loader, valset_loader, optimizer, criterion, max_epochs, early_stop, verbose, gpu, plot)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_54830/4156769339.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, trainset_loader, optimizer, criterion, gpu)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mout_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mbatch_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_54830/3684482469.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x-\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelation_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelation_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch1.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_54830/3684482469.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, adj)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0msupport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msupport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sup-\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (15744x64 and 492x492)"
     ]
    }
   ],
   "source": [
    "data=read_data(\"../data/sz_taxi_202006/sz_taxi_202006_5min_recovered_flow_dlt.pkl\", transpose=True)\n",
    "train_loader, val_loader, test_loader=get_dataloaders(data, 12, 12)\n",
    "model=DontKnowWhat2EatNN(embed_vectors, 12, 12)\n",
    "criterion=torch.nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train(model, train_loader, val_loader, test_loader, criterion, gpu=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8de3ed3a1560fc9f13af5266ca08823e90fcdd17bfae2dfaf8ec66fe041076c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('dz')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
