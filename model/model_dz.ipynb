{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cseadmin/dz/TrafficFlowModel/model'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "import datetime\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "DATA_PATH=\"../data/sz_taxi_202006/\"\n",
    "vec_size=512\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1751602"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[[198, Timestamp('2020-06-01 00:43:29'), 56.0],\n",
       " [199, Timestamp('2020-06-01 00:43:49'), 55.5],\n",
       " [448, Timestamp('2020-06-01 00:44:09'), 55.0]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_list=np.load(\"../data/sz_taxi_202006/sz_taxi_202006_traj_list.npy\", allow_pickle=True)\n",
    "\n",
    "len(traj_list)\n",
    "traj_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1751602"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[198, 199, 448]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tracks=[]\n",
    "for traj in traj_list:\n",
    "    road_ids=[]\n",
    "    for point in traj:\n",
    "        road_ids.append(point[0])\n",
    "    all_tracks.append(road_ids)\n",
    "\n",
    "len(all_tracks)\n",
    "all_tracks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_all_traj=Word2Vec(all_tracks, sg=1, hs=1, vector_size=vec_size, window=10, min_count=1, workers=4)\n",
    "\n",
    "w2v_all_traj.save(os.path.join(DATA_PATH, f\"w2v_all_traj_{vec_size}.model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7991076111793518"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_all_traj=Word2Vec.load(os.path.join(DATA_PATH, f\"w2v_all_traj_{vec_size}.model\"))\n",
    "wv=w2v_all_traj.wv\n",
    "\n",
    "wv.distance(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04961416,  0.03711881,  0.00701622, -0.02471929,  0.04195437,\n",
       "        0.05551275, -0.0024164 ,  0.03509161, -0.01095492,  0.05997162],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=np.argsort(wv.index_to_key)\n",
    "embed_vectors=wv.get_normed_vectors()\n",
    "\n",
    "embed_vectors=embed_vectors[index]\n",
    "embed_vectors[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 492)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1.0000002 , 0.13911077, 0.18122032, 0.20089237, 0.2514562 ,\n",
       "       0.16970405, 0.21216552, 0.12217825, 0.12732378, 0.13965628],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = embed_vectors @ embed_vectors.T\n",
    "\n",
    "correlation_matrix.shape\n",
    "correlation_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0183, 0.0183, 0.0183,  ..., 0.0183, 0.0183, 0.0183],\n",
       "        [0.0183, 0.0183, 0.0183,  ..., 0.0183, 0.0183, 0.0183],\n",
       "        [0.0183, 0.0183, 0.0183,  ..., 0.0183, 0.0183, 0.0183],\n",
       "        ...,\n",
       "        [0.0183, 0.0183, 0.0183,  ..., 0.0183, 0.0183, 0.0183],\n",
       "        [0.0183, 0.0183, 0.0183,  ..., 0.0183, 0.0183, 0.0183],\n",
       "        [0.0183, 0.0183, 0.0183,  ..., 0.0183, 0.0183, 0.0183]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DontKnowWhat2EatNN(torch.nn.Module):\n",
    "    def __init__(self, graph_embed_vectors, num_heads=8, drop_rate=0):\n",
    "        super(DontKnowWhat2EatNN, self).__init__()\n",
    "        \n",
    "        self.graph_embed_vectors=torch.FloatTensor(graph_embed_vectors.reshape(graph_embed_vectors.shape[0], 1, graph_embed_vectors.shape[1]))\n",
    "        self.embed_dim=graph_embed_vectors.shape[-1]\n",
    "        self.num_heads=num_heads\n",
    "        self.drop_rate=drop_rate\n",
    "        \n",
    "        self.mh_attention=torch.nn.MultiheadAttention(self.embed_dim, self.num_heads, dropout=self.drop_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, N, in_step, num_features)\n",
    "        \"\"\"\n",
    "        \n",
    "        attn_output, attn_output_weights=self.mh_attention.forward(self.graph_embed_vectors, self.graph_embed_vectors, self.graph_embed_vectors)\n",
    "        attn_output=attn_output.reshape(attn_output.shape[0], attn_output.shape[2])\n",
    "        correlation_matrix=attn_output @ attn_output.T\n",
    "        \n",
    "        return correlation_matrix\n",
    "    \n",
    "\n",
    "model=DontKnowWhat2EatNN(embed_vectors)\n",
    "model.forward(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, trainset_loader, optimizer, criterion, gpu=True):\n",
    "    model.train()\n",
    "    batch_loss_list=[]\n",
    "    for x_batch, y_batch in trainset_loader:\n",
    "        if gpu and torch.cuda.is_available():\n",
    "            x_batch = x_batch.cuda()\n",
    "            y_batch = y_batch.cuda()\n",
    "\n",
    "        out_batch = model.forward(x_batch)\n",
    "        loss = criterion.forward(out_batch, y_batch)\n",
    "        batch_loss_list.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return sum(batch_loss_list)/len(batch_loss_list)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model, valset_loader, criterion, gpu=True):\n",
    "    model.eval()\n",
    "    batch_loss_list=[]\n",
    "    for x_batch, y_batch in valset_loader:\n",
    "        if gpu and torch.cuda.is_available():\n",
    "            x_batch = x_batch.cuda()\n",
    "            y_batch = y_batch.cuda()\n",
    "\n",
    "        out_batch = model.forward(x_batch)\n",
    "        loss = criterion.forward(out_batch, y_batch)\n",
    "        batch_loss_list.append(loss.item())\n",
    "\n",
    "    return sum(batch_loss_list)/len(batch_loss_list)\n",
    "\n",
    "def train(model, trainset_loader, valset_loader, optimizer, criterion, max_epochs=100, early_stop=10, verbose=1, gpu=True, plot=True):\n",
    "    wait=0\n",
    "    min_val_loss=np.inf\n",
    "    \n",
    "    train_loss_list=[]\n",
    "    val_loss_list=[]\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        train_loss=train_one_epoch(model, trainset_loader, optimizer, criterion, gpu)\n",
    "        train_loss_list.append(train_loss)\n",
    "        \n",
    "        val_loss=eval_model(model, valset_loader, criterion)\n",
    "        val_loss_list.append(val_loss)\n",
    "        \n",
    "        if (epoch+1)%verbose==0:\n",
    "            print(datetime.datetime.now(), \"Epoch\", epoch,\n",
    "                  \"\\tTrain Loss = %.5f\"%train_loss,\n",
    "                  \"\\tVal Loss = %.5f\"%val_loss)\n",
    "        \n",
    "        if val_loss<min_val_loss:\n",
    "            wait=0\n",
    "            min_val_loss=val_loss\n",
    "            best_epoch=epoch\n",
    "        else:\n",
    "            wait+=1\n",
    "            if wait >= early_stop:\n",
    "                print(\"Early stopping at epoch: %d\" % epoch)\n",
    "                break\n",
    "        \n",
    "    if plot:\n",
    "        plt.plot(range(0, epoch+1), train_loss_list, \"-\", label=\"Train Loss\")\n",
    "        plt.plot(range(0, epoch+1), val_loss_list, \"-\", label=\"Val Loss\")\n",
    "        plt.title(\"Epoch-Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8de3ed3a1560fc9f13af5266ca08823e90fcdd17bfae2dfaf8ec66fe041076c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('dz')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
