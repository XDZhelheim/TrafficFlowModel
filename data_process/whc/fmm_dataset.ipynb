{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cseadmin/dz/TrafficFlowModel/data_process/whc'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import json\n",
    "import osmnx as ox\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../data/\"\n",
    "TAXI_DATA_PATH = \"../../data/taxi_after_proc/clean202006\"\n",
    "DATASET = \"whc\"\n",
    "\n",
    "MIN_LAT = 22.518177550691007\n",
    "MAX_LAT = 22.55855667275185\n",
    "MIN_LNG = 114.04103544140904\n",
    "MAX_LNG = 114.099681037508\n",
    "\n",
    "START_DAY = 1\n",
    "END_DAY = 30\n",
    "\n",
    "DOWNSAMPLING_INTERVAL = 10 #s\n",
    "TRAJ_SPLIT_INTERVAL = 600\n",
    "FLOW_AGG_INTERVAL_MINUTE = 5\n",
    "\n",
    "def contains(lat, lng):\n",
    "    return lat >= MIN_LAT and lat <= MAX_LAT and lng >= MIN_LNG and lng <= MAX_LNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def distance(origin, destination):\n",
    "    \"\"\"\n",
    "    Calculate the Haversine distance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    origin : tuple of float\n",
    "        (lat, long)\n",
    "    destination : tuple of float\n",
    "        (lat, long)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    distance_in_km : float\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> origin = (48.1372, 11.5756)  # Munich\n",
    "    >>> destination = (52.5186, 13.4083)  # Berlin\n",
    "    >>> round(distance(origin, destination), 1)\n",
    "    504.2\n",
    "    \"\"\"\n",
    "    lat1, lon1 = origin\n",
    "    lat2, lon2 = destination\n",
    "    radius = 6371  # km\n",
    "    \n",
    "    if lat1 == -1 or lon1 == -1 or lat2 == -1 or lon2 == -1:\n",
    "        return 0\n",
    "\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = (math.sin(dlat / 2) * math.sin(dlat / 2) +\n",
    "         math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) *\n",
    "         math.sin(dlon / 2) * math.sin(dlon / 2))\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 51843/649565 [23:36<4:57:06, 33.53it/s] "
     ]
    }
   ],
   "source": [
    "gps_file = open(os.path.join(DATA_PATH, DATASET, f\"fmm_{DATASET}\", \"gps.csv\"), \"w\")\n",
    "trash = gps_file.write(\"id;x;y;time;speed\\n\")\n",
    "\n",
    "timedelta_downsampling = pd.Timedelta(seconds=DOWNSAMPLING_INTERVAL)\n",
    "timedelta_traj_split = pd.Timedelta(seconds=TRAJ_SPLIT_INTERVAL)\n",
    "\n",
    "traj_counter = 0\n",
    "for taxi_file in tqdm(sorted(os.listdir(TAXI_DATA_PATH))):\n",
    "    df_taxi = pd.read_pickle(os.path.join(TAXI_DATA_PATH, taxi_file))\n",
    "    trash=df_taxi.drop_duplicates(\"gps_time\", inplace=True) # 这一步其实该在数据清洗的时候做: 一辆车同一时间出现在不同位置\n",
    "    if len(df_taxi) < 2:\n",
    "        continue\n",
    "    \n",
    "    # check first row's speed\n",
    "    first_row = df_taxi.iloc[0]\n",
    "    if first_row[\"speed\"] == 0:\n",
    "        second_row = df_taxi.iloc[1]\n",
    "        dist = distance((first_row[\"lat\"], first_row[\"lng\"]), (second_row[\"lat\"], second_row[\"lng\"]))\n",
    "        time_delta = (second_row[\"gps_time\"] - first_row[\"gps_time\"]).total_seconds() / 3600 # hour\n",
    "        df_taxi.loc[df_taxi.index[0], \"speed\"] = dist / time_delta # first_row is a copy, must operate on df\n",
    "\n",
    "    line_buffer = []\n",
    "    # (index, lat, lon, time, speed)\n",
    "    last_row = (-1, -1, -1, df_taxi.iloc[0][\"gps_time\"] + pd.Timedelta(seconds=-TRAJ_SPLIT_INTERVAL), -1)\n",
    "    # last_time = df_taxi.iloc[0][\"gps_time\"] + pd.Timedelta(seconds=-TRAJ_SPLIT_INTERVAL)\n",
    "    for row in df_taxi.itertuples():\n",
    "        row = list(row)\n",
    "        if not contains(row[1], row[2]):\n",
    "            continue\n",
    "        if row[3] - last_row[3] < timedelta_downsampling:  # resample: drop <30s\n",
    "            continue\n",
    "        # if row[4] > 60: # drop speed > 60km/h\n",
    "        #     continue\n",
    "        if row[4] == 0:\n",
    "            dist = distance((row[1], row[2]), (last_row[1], last_row[2]))\n",
    "            time_delta = (row[3] - last_row[3]).total_seconds() / 3600 # hour\n",
    "            row[4] = dist / time_delta\n",
    "        if row[3] - last_row[3] > timedelta_traj_split:\n",
    "            if len(line_buffer) > 1:  # only store length>1 traj\n",
    "                trash = gps_file.write(\"\".join(line_buffer))\n",
    "                traj_counter += 1\n",
    "            line_buffer = []\n",
    "\n",
    "        last_row = row\n",
    "\n",
    "        line_buffer.append(f\"{traj_counter};{row[2]};{row[1]};{row[3]};{row[4]}\\n\")\n",
    "\n",
    "gps_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/cyang-kth/fmm/issues/166\n",
    "# https://github.com/cyang-kth/fmm/blob/master/example/osmnx_example/README.md\n",
    "\n",
    "os.system(\n",
    "    \"ubodt_gen --network {} --network_id fid --source u --target v --output {} --delta 0.03 --use_omp\"\n",
    "    .format(\n",
    "        os.path.join(DATA_PATH, DATASET, f\"fmm_{DATASET}\", \"edges.shp\"),\n",
    "        os.path.join(DATA_PATH, DATASET, f\"fmm_{DATASET}\", \"ubodt.txt\")))\n",
    "os.system(\n",
    "    \"fmm --ubodt {} --network {} --network_id fid --source u --target v --gps {} --gps_point -k 8 -r 0.003 -e 0.0005 --output {} --use_omp --output_fields id,opath,cpath > {} 2>&1\"\n",
    "    .format(\n",
    "        os.path.join(DATA_PATH, DATASET, f\"fmm_{DATASET}\", \"ubodt.txt\"),\n",
    "        os.path.join(DATA_PATH, DATASET, f\"fmm_{DATASET}\", \"edges.shp\"),\n",
    "        os.path.join(DATA_PATH, DATASET, f\"fmm_{DATASET}\", \"gps.csv\"),\n",
    "        os.path.join(DATA_PATH, DATASET, f\"fmm_{DATASET}\", \"mr.txt\"),\n",
    "        os.path.join(DATA_PATH, DATASET, f\"fmm_{DATASET}\", \"fmm.log\")))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8de3ed3a1560fc9f13af5266ca08823e90fcdd17bfae2dfaf8ec66fe041076c"
  },
  "kernelspec": {
   "display_name": "Python [conda env:dz] *",
   "language": "python",
   "name": "conda-env-dz-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
