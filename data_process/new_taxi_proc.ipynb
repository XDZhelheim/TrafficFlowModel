{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d637f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cseadmin/data/cys/TrafficFlowModel/data_process'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gp\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import folium\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d304256",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['../data/taxi/2019-12-10/2019-12-10_7',\n",
       "  '../data/taxi/2019-12-10/2019-12-10_4',\n",
       "  '../data/taxi/2019-12-10/2019-12-10_5',\n",
       "  '../data/taxi/2019-12-10/2019-12-10_8',\n",
       "  '../data/taxi/2019-12-10/2019-12-10_6',\n",
       "  '../data/taxi/2019-12-10/2019-12-10_1',\n",
       "  '../data/taxi/2019-12-10/2019-12-10_0',\n",
       "  '../data/taxi/2019-12-10/2019-12-10_3',\n",
       "  '../data/taxi/2019-12-10/2019-12-10_2'],\n",
       " ['../data/taxi/2019-12-13/2019-12-13_1',\n",
       "  '../data/taxi/2019-12-13/2019-12-13_0'],\n",
       " ['../data/taxi/2019-12-07/2019-12-07_5',\n",
       "  '../data/taxi/2019-12-07/2019-12-07_0',\n",
       "  '../data/taxi/2019-12-07/2019-12-07_8',\n",
       "  '../data/taxi/2019-12-07/2019-12-07_1',\n",
       "  '../data/taxi/2019-12-07/2019-12-07_6',\n",
       "  '../data/taxi/2019-12-07/2019-12-07_4',\n",
       "  '../data/taxi/2019-12-07/2019-12-07_3',\n",
       "  '../data/taxi/2019-12-07/2019-12-07_2',\n",
       "  '../data/taxi/2019-12-07/2019-12-07_7'],\n",
       " ['../data/taxi/2019-12-08/2019-12-08_8',\n",
       "  '../data/taxi/2019-12-08/2019-12-08_2',\n",
       "  '../data/taxi/2019-12-08/2019-12-08_6',\n",
       "  '../data/taxi/2019-12-08/2019-12-08_5',\n",
       "  '../data/taxi/2019-12-08/2019-12-08_0',\n",
       "  '../data/taxi/2019-12-08/2019-12-08_7',\n",
       "  '../data/taxi/2019-12-08/2019-12-08_3',\n",
       "  '../data/taxi/2019-12-08/2019-12-08_4',\n",
       "  '../data/taxi/2019-12-08/2019-12-08_1'],\n",
       " ['../data/taxi/2019-12-02/2019-12-02_7',\n",
       "  '../data/taxi/2019-12-02/2019-12-02_1',\n",
       "  '../data/taxi/2019-12-02/2019-12-02_0',\n",
       "  '../data/taxi/2019-12-02/2019-12-02_4',\n",
       "  '../data/taxi/2019-12-02/2019-12-02_6',\n",
       "  '../data/taxi/2019-12-02/2019-12-02_3',\n",
       "  '../data/taxi/2019-12-02/2019-12-02_5',\n",
       "  '../data/taxi/2019-12-02/2019-12-02_2'],\n",
       " ['../data/taxi/2019-12-11/2019-12-11_5',\n",
       "  '../data/taxi/2019-12-11/2019-12-11_0',\n",
       "  '../data/taxi/2019-12-11/2019-12-11_2',\n",
       "  '../data/taxi/2019-12-11/2019-12-11_3',\n",
       "  '../data/taxi/2019-12-11/2019-12-11_1',\n",
       "  '../data/taxi/2019-12-11/2019-12-11_7',\n",
       "  '../data/taxi/2019-12-11/2019-12-11_8',\n",
       "  '../data/taxi/2019-12-11/2019-12-11_6',\n",
       "  '../data/taxi/2019-12-11/2019-12-11_4'],\n",
       " ['../data/taxi/2019-12-05/2019-12-05_8',\n",
       "  '../data/taxi/2019-12-05/2019-12-05_4',\n",
       "  '../data/taxi/2019-12-05/2019-12-05_6',\n",
       "  '../data/taxi/2019-12-05/2019-12-05_1',\n",
       "  '../data/taxi/2019-12-05/2019-12-05_7',\n",
       "  '../data/taxi/2019-12-05/2019-12-05_5',\n",
       "  '../data/taxi/2019-12-05/2019-12-05_0',\n",
       "  '../data/taxi/2019-12-05/2019-12-05_2',\n",
       "  '../data/taxi/2019-12-05/2019-12-05_3'],\n",
       " ['../data/taxi/2019-12-12/2019-12-12_0',\n",
       "  '../data/taxi/2019-12-12/2019-12-12_5',\n",
       "  '../data/taxi/2019-12-12/2019-12-12_4',\n",
       "  '../data/taxi/2019-12-12/2019-12-12_7',\n",
       "  '../data/taxi/2019-12-12/2019-12-12_8',\n",
       "  '../data/taxi/2019-12-12/2019-12-12_6',\n",
       "  '../data/taxi/2019-12-12/2019-12-12_3',\n",
       "  '../data/taxi/2019-12-12/2019-12-12_2',\n",
       "  '../data/taxi/2019-12-12/2019-12-12_1'],\n",
       " ['../data/taxi/2019-12-03/2019-12-03_3',\n",
       "  '../data/taxi/2019-12-03/2019-12-03_4',\n",
       "  '../data/taxi/2019-12-03/2019-12-03_5',\n",
       "  '../data/taxi/2019-12-03/2019-12-03_0',\n",
       "  '../data/taxi/2019-12-03/2019-12-03_7',\n",
       "  '../data/taxi/2019-12-03/2019-12-03_2',\n",
       "  '../data/taxi/2019-12-03/2019-12-03_6',\n",
       "  '../data/taxi/2019-12-03/2019-12-03_8',\n",
       "  '../data/taxi/2019-12-03/2019-12-03_1'],\n",
       " ['../data/taxi/2019-12-04/2019-12-04_8',\n",
       "  '../data/taxi/2019-12-04/2019-12-04_2',\n",
       "  '../data/taxi/2019-12-04/2019-12-04_6',\n",
       "  '../data/taxi/2019-12-04/2019-12-04_3',\n",
       "  '../data/taxi/2019-12-04/2019-12-04_1',\n",
       "  '../data/taxi/2019-12-04/2019-12-04_0',\n",
       "  '../data/taxi/2019-12-04/2019-12-04_4',\n",
       "  '../data/taxi/2019-12-04/2019-12-04_5',\n",
       "  '../data/taxi/2019-12-04/2019-12-04_7'],\n",
       " ['../data/taxi/2019-12-06/2019-12-06_8',\n",
       "  '../data/taxi/2019-12-06/2019-12-06_3',\n",
       "  '../data/taxi/2019-12-06/2019-12-06_7',\n",
       "  '../data/taxi/2019-12-06/2019-12-06_5',\n",
       "  '../data/taxi/2019-12-06/2019-12-06_4',\n",
       "  '../data/taxi/2019-12-06/2019-12-06_1',\n",
       "  '../data/taxi/2019-12-06/2019-12-06_2',\n",
       "  '../data/taxi/2019-12-06/2019-12-06_0',\n",
       "  '../data/taxi/2019-12-06/2019-12-06_6'],\n",
       " ['../data/taxi/2019-12-01/2019-12-01_7',\n",
       "  '../data/taxi/2019-12-01/2019-12-01_6',\n",
       "  '../data/taxi/2019-12-01/2019-12-01_0',\n",
       "  '../data/taxi/2019-12-01/2019-12-01_2',\n",
       "  '../data/taxi/2019-12-01/2019-12-01_8',\n",
       "  '../data/taxi/2019-12-01/2019-12-01_3',\n",
       "  '../data/taxi/2019-12-01/2019-12-01_1',\n",
       "  '../data/taxi/2019-12-01/2019-12-01_4',\n",
       "  '../data/taxi/2019-12-01/2019-12-01_5'],\n",
       " ['../data/taxi/2019-12-09/2019-12-09_0',\n",
       "  '../data/taxi/2019-12-09/2019-12-09_5',\n",
       "  '../data/taxi/2019-12-09/2019-12-09_6',\n",
       "  '../data/taxi/2019-12-09/2019-12-09_1',\n",
       "  '../data/taxi/2019-12-09/2019-12-09_2',\n",
       "  '../data/taxi/2019-12-09/2019-12-09_4',\n",
       "  '../data/taxi/2019-12-09/2019-12-09_7',\n",
       "  '../data/taxi/2019-12-09/2019-12-09_8',\n",
       "  '../data/taxi/2019-12-09/2019-12-09_3']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = os.walk(\"../data/taxi\")\n",
    "all_files = []\n",
    "for root,ds,fs in root_path:\n",
    "    days = []\n",
    "    for f in fs:\n",
    "        full_path = os.path.join(root,f)\n",
    "        days.append(full_path)\n",
    "    if len(days)==0:\n",
    "        continue\n",
    "    all_files.append(days)\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8264a9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 1/9 [02:48<22:30, 168.81s/it]\u001b[A\n",
      " 22%|██▏       | 2/9 [05:27<18:59, 162.73s/it]\u001b[A\n",
      " 33%|███▎      | 3/9 [08:04<16:00, 160.03s/it]\u001b[A\n",
      " 44%|████▍     | 4/9 [10:44<13:21, 160.36s/it]\u001b[A\n",
      " 56%|█████▌    | 5/9 [13:27<10:44, 161.22s/it]\u001b[A\n",
      " 67%|██████▋   | 6/9 [16:11<08:06, 162.03s/it]\u001b[A\n",
      " 78%|███████▊  | 7/9 [18:54<05:24, 162.26s/it]\u001b[A\n",
      " 89%|████████▉ | 8/9 [21:39<02:43, 163.13s/it]\u001b[A\n",
      "100%|██████████| 9/9 [23:23<00:00, 155.99s/it]\u001b[A\n",
      "  8%|▊         | 1/13 [23:23<4:40:47, 1403.93s/it]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [02:35<18:11, 155.89s/it]\u001b[A\n",
      " 25%|██▌       | 2/8 [05:07<15:21, 153.58s/it]\u001b[A\n",
      " 38%|███▊      | 3/8 [07:48<13:03, 156.72s/it]\u001b[A\n",
      " 50%|█████     | 4/8 [10:31<10:37, 159.34s/it]\u001b[A\n",
      " 62%|██████▎   | 5/8 [13:14<08:01, 160.52s/it]\u001b[A\n",
      " 75%|███████▌  | 6/8 [15:56<05:22, 161.13s/it]\u001b[A\n",
      " 88%|████████▊ | 7/8 [18:39<02:41, 161.87s/it]\u001b[A\n",
      "100%|██████████| 8/8 [21:23<00:00, 160.46s/it]\u001b[A\n",
      " 15%|█▌        | 2/13 [44:47<4:04:25, 1333.22s/it]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 1/9 [02:38<21:06, 158.26s/it]\u001b[A\n",
      " 22%|██▏       | 2/9 [05:07<17:49, 152.85s/it]\u001b[A\n",
      " 33%|███▎      | 3/9 [07:43<15:26, 154.49s/it]\u001b[A\n",
      " 44%|████▍     | 4/9 [10:26<13:08, 157.63s/it]\u001b[A\n",
      " 56%|█████▌    | 5/9 [13:08<10:37, 159.47s/it]\u001b[A\n",
      " 67%|██████▋   | 6/9 [15:53<08:03, 161.04s/it]\u001b[A\n",
      " 78%|███████▊  | 7/9 [18:36<05:23, 161.99s/it]\u001b[A\n",
      " 89%|████████▉ | 8/9 [21:21<02:42, 162.66s/it]\u001b[A\n",
      "100%|██████████| 9/9 [22:56<00:00, 152.99s/it]\u001b[A\n",
      " 23%|██▎       | 3/13 [1:07:44<3:45:31, 1353.19s/it]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 1/9 [02:36<20:53, 156.65s/it]\u001b[A\n",
      " 22%|██▏       | 2/9 [05:06<17:50, 152.87s/it]\u001b[A\n",
      " 33%|███▎      | 3/9 [07:45<15:32, 155.41s/it]\u001b[A\n",
      " 44%|████▍     | 4/9 [10:29<13:14, 158.87s/it]\u001b[A\n",
      " 56%|█████▌    | 5/9 [13:11<10:39, 159.92s/it]\u001b[A\n",
      " 67%|██████▋   | 6/9 [15:54<08:03, 161.18s/it]\u001b[A\n",
      " 78%|███████▊  | 7/9 [18:38<05:24, 162.04s/it]\u001b[A\n",
      " 89%|████████▉ | 8/9 [21:23<02:42, 162.76s/it]\u001b[A\n",
      "100%|██████████| 9/9 [22:59<00:00, 153.28s/it]\u001b[A\n",
      " 31%|███       | 4/13 [1:30:44<3:24:32, 1363.58s/it]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 1/9 [02:35<20:41, 155.16s/it]\u001b[A\n",
      " 22%|██▏       | 2/9 [05:09<18:01, 154.46s/it]\u001b[A\n",
      " 33%|███▎      | 3/9 [07:47<15:37, 156.26s/it]\u001b[A\n",
      " 44%|████▍     | 4/9 [10:31<13:17, 159.46s/it]\u001b[A\n",
      " 56%|█████▌    | 5/9 [13:16<10:44, 161.15s/it]\u001b[A\n",
      " 67%|██████▋   | 6/9 [16:03<08:09, 163.15s/it]\u001b[A\n",
      " 78%|███████▊  | 7/9 [18:48<05:27, 163.83s/it]\u001b[A\n",
      " 89%|████████▉ | 8/9 [21:34<02:44, 164.67s/it]\u001b[A\n",
      "100%|██████████| 9/9 [23:08<00:00, 154.32s/it]\u001b[A\n",
      " 38%|███▊      | 5/13 [1:53:52<3:03:01, 1372.69s/it]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 1/9 [02:38<21:06, 158.30s/it]\u001b[A\n",
      " 22%|██▏       | 2/9 [05:12<18:10, 155.85s/it]\u001b[A\n",
      " 33%|███▎      | 3/9 [07:54<15:52, 158.81s/it]\u001b[A\n",
      " 44%|████▍     | 4/9 [10:40<13:27, 161.52s/it]\u001b[A\n",
      " 56%|█████▌    | 5/9 [13:26<10:52, 163.13s/it]\u001b[A\n",
      " 67%|██████▋   | 6/9 [16:13<08:12, 164.33s/it]\u001b[A\n",
      " 78%|███████▊  | 7/9 [19:00<05:30, 165.45s/it]\u001b[A\n",
      " 89%|████████▉ | 8/9 [21:50<02:46, 166.63s/it]\u001b[A\n",
      "100%|██████████| 9/9 [23:33<00:00, 157.02s/it]\u001b[A\n",
      " 46%|████▌     | 6/13 [2:17:26<2:41:45, 1386.47s/it]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 1/9 [02:41<21:33, 161.75s/it]\u001b[A\n",
      " 22%|██▏       | 2/9 [05:18<18:31, 158.80s/it]\u001b[A\n",
      " 33%|███▎      | 3/9 [07:56<15:51, 158.65s/it]\u001b[A\n",
      " 44%|████▍     | 4/9 [10:41<13:24, 160.91s/it]\u001b[A\n",
      " 56%|█████▌    | 5/9 [13:28<10:52, 163.10s/it]\u001b[A\n",
      " 67%|██████▋   | 6/9 [16:14<08:12, 164.24s/it]\u001b[A\n",
      " 78%|███████▊  | 7/9 [19:03<05:31, 165.73s/it]\u001b[A\n",
      " 89%|████████▉ | 8/9 [21:52<02:46, 166.73s/it]\u001b[A\n",
      "100%|██████████| 9/9 [23:36<00:00, 157.42s/it]\u001b[A\n",
      " 54%|█████▍    | 7/13 [2:41:02<2:19:38, 1396.38s/it]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 1/9 [02:41<21:30, 161.31s/it]\u001b[A\n",
      " 22%|██▏       | 2/9 [05:19<18:35, 159.35s/it]\u001b[A\n",
      " 33%|███▎      | 3/9 [07:56<15:49, 158.20s/it]\u001b[A\n",
      " 44%|████▍     | 4/9 [10:38<13:19, 159.93s/it]\u001b[A\n",
      " 56%|█████▌    | 5/9 [13:25<10:48, 162.24s/it]\u001b[A\n",
      " 67%|██████▋   | 6/9 [16:11<08:10, 163.58s/it]\u001b[A\n",
      " 78%|███████▊  | 7/9 [18:56<05:28, 164.04s/it]\u001b[A\n",
      " 89%|████████▉ | 8/9 [21:43<02:45, 165.02s/it]\u001b[A\n",
      "100%|██████████| 9/9 [23:23<00:00, 155.98s/it]\u001b[A\n",
      " 62%|██████▏   | 8/13 [3:04:26<1:56:33, 1398.75s/it]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 1/9 [02:35<20:46, 155.86s/it]\u001b[A\n",
      " 22%|██▏       | 2/9 [05:10<18:05, 155.01s/it]\u001b[A\n",
      " 33%|███▎      | 3/9 [07:52<15:48, 158.09s/it]\u001b[A\n",
      " 44%|████▍     | 4/9 [10:37<13:25, 161.09s/it]\u001b[A\n",
      " 56%|█████▌    | 5/9 [13:24<10:51, 162.98s/it]\u001b[A\n",
      " 67%|██████▋   | 6/9 [16:10<08:12, 164.00s/it]\u001b[A\n",
      " 78%|███████▊  | 7/9 [18:55<05:29, 164.51s/it]\u001b[A\n",
      " 89%|████████▉ | 8/9 [21:40<02:44, 164.70s/it]\u001b[A\n",
      "100%|██████████| 9/9 [23:15<00:00, 155.09s/it]\u001b[A\n",
      " 69%|██████▉   | 9/13 [3:27:42<1:33:11, 1397.83s/it]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 1/9 [02:36<20:53, 156.71s/it]\u001b[A\n",
      " 22%|██▏       | 2/9 [05:12<18:11, 155.94s/it]\u001b[A\n",
      " 33%|███▎      | 3/9 [07:51<15:46, 157.67s/it]\u001b[A\n",
      " 44%|████▍     | 4/9 [10:37<13:24, 160.87s/it]\u001b[A\n",
      " 56%|█████▌    | 5/9 [13:22<10:49, 162.47s/it]\u001b[A\n",
      " 67%|██████▋   | 6/9 [16:09<08:11, 163.99s/it]\u001b[A\n",
      " 78%|███████▊  | 7/9 [18:54<05:28, 164.16s/it]\u001b[A\n",
      " 89%|████████▉ | 8/9 [21:40<02:44, 164.66s/it]\u001b[A\n",
      "100%|██████████| 9/9 [23:17<00:00, 155.32s/it]\u001b[A\n",
      " 77%|███████▋  | 10/13 [3:51:00<1:09:53, 1397.84s/it]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 1/9 [02:37<20:56, 157.05s/it]\u001b[A\n",
      " 22%|██▏       | 2/9 [05:10<18:02, 154.66s/it]\u001b[A\n",
      " 33%|███▎      | 3/9 [07:48<15:38, 156.33s/it]\u001b[A\n",
      " 44%|████▍     | 4/9 [10:35<13:23, 160.68s/it]\u001b[A\n",
      " 56%|█████▌    | 5/9 [13:22<10:51, 162.94s/it]\u001b[A\n",
      " 67%|██████▋   | 6/9 [16:07<08:11, 163.72s/it]\u001b[A\n",
      " 78%|███████▊  | 7/9 [18:54<05:29, 164.63s/it]\u001b[A\n",
      " 89%|████████▉ | 8/9 [21:40<02:45, 165.08s/it]\u001b[A\n",
      "100%|██████████| 9/9 [23:20<00:00, 155.57s/it]\u001b[A\n",
      " 85%|████████▍ | 11/13 [4:14:20<46:37, 1398.55s/it]  \n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 1/9 [02:36<20:54, 156.77s/it]\u001b[A\n",
      " 22%|██▏       | 2/9 [05:10<18:06, 155.17s/it]\u001b[A\n",
      " 33%|███▎      | 3/9 [07:49<15:39, 156.56s/it]\u001b[A\n",
      " 44%|████▍     | 4/9 [10:36<13:25, 161.02s/it]\u001b[A\n",
      " 56%|█████▌    | 5/9 [13:21<10:48, 162.15s/it]\u001b[A\n",
      " 67%|██████▋   | 6/9 [16:09<08:12, 164.14s/it]\u001b[A\n",
      " 78%|███████▊  | 7/9 [18:52<05:27, 163.91s/it]\u001b[A\n",
      " 89%|████████▉ | 8/9 [21:39<02:44, 164.83s/it]\u001b[A\n",
      "100%|██████████| 9/9 [23:16<00:00, 155.13s/it]\u001b[A\n",
      " 92%|█████████▏| 12/13 [4:37:36<23:17, 1397.83s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [02:03<02:03, 123.60s/it]\u001b[A\n",
      "100%|██████████| 2/2 [04:01<00:00, 120.53s/it]\u001b[A\n",
      "100%|██████████| 13/13 [4:41:37<00:00, 1299.83s/it]\n"
     ]
    }
   ],
   "source": [
    "names=[\"sys_time\", \"license_number\", \"lng\", \"lat\", \"gps_time\", \"EMPTY1\", \"speed\", \"direction\", \"car_status\",\"alarm_status\",\n",
    "       \"EMPTY2\", \"EMPTY3\", \"license_color\", \"recorder_speed\", \"mileage\", \"height\", \"EMPTY4\"]\n",
    "\n",
    "# 将数据进行初步处理\n",
    "dest_path = \"../data/taxi_after_proc/proc_segment/\"\n",
    "all_files.sort()\n",
    "for each_day in tqdm(all_files):\n",
    "    each_day.sort()\n",
    "    \n",
    "    for each_time in tqdm(each_day):\n",
    "        records = pd.read_csv(each_time,names=names)\n",
    "        group = records.groupby(\"license_number\")\n",
    "        for each_lincense, each_record in group:\n",
    "            posi = each_record[['lat', 'lng', 'gps_time', 'speed', 'direction', 'car_status']]\n",
    "            # 按gps时间排序，并去重\n",
    "            posi['gps_time'] = pd.to_datetime(posi['gps_time'])\n",
    "            posi.sort_values(by=\"gps_time\", inplace=True, ascending=True)\n",
    "            posi = posi.drop_duplicates()\n",
    "            # 去除错误日期的记录\n",
    "            open_day = '2019-12-01'\n",
    "            close_day = '2019-12-14'\n",
    "            posi = posi[(posi['gps_time'] > open_day) & (posi['gps_time'] < close_day)]\n",
    "            # 去除速度为0的记录\n",
    "            posi = posi.loc[(posi != 0).all(axis=1)]\n",
    "            # 去除数量过少的记录\n",
    "            if len(posi) < 30:\n",
    "                continue\n",
    "            posi.to_csv(dest_path+each_time[-7:]+each_lincense+\".csv\",index=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a431ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=os.listdir(\"../data/taxi_after_proc/proc_segment/\")\n",
    "car_set=set()\n",
    "\n",
    "for file in files:\n",
    "    car=file[7:-4]\n",
    "    car_set.add(car)\n",
    "\n",
    "days=[\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "\n",
    "for car in car_set:\n",
    "    for day in days:\n",
    "        df_all=pd.DataFrame()\n",
    "        for i in range(10):\n",
    "            try:\n",
    "                df_all=df_all.append(pd.read_csv(\"../data/taxi_after_proc/proc_segment/12-{}_{}{}.csv\".format(day, i, car)))\n",
    "                df_all = df_all.drop_duplicates(subset=\"gps_time\",keep=\"first\")\n",
    "                df_all = df_all[(df_all['gps_time']>'2019-12-01')&(df_all['gps_time']<'2019-12-14')]\n",
    "                df_all = df_all[(df_all['speed']>0)&(df_all['speed']<150)]\n",
    "#                 print(df_all)\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "        df_all.to_csv(\"../data/taxi_after_proc/merged/12-{}_{}.csv\".format(day, car))\n",
    "\n",
    "for file in os.listdir(\"../data/taxi_after_proc/merged/\"):\n",
    "    df=pd.read_csv(\"../data/taxi_after_proc/merged/\"+file)\n",
    "    try:\n",
    "        df=df.drop(columns=\"Unnamed: 0\")\n",
    "    except KeyError:\n",
    "        continue\n",
    "    df.to_csv(\"../data/taxi_after_proc/merged/\"+file, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b19829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接下来是处理，查看GPS track的\n",
    "path = \"../data/taxi_after_proc/merged/\"\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    print(path+file)\n",
    "    tracks = pd.read_csv(path+file)\n",
    "    tracks\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_p = \"../data/taxi_after_proc/merged/12-11_粤BD99105.csv\"\n",
    "tracks = pd.read_csv(test_p)\n",
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc07495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[22.565050, 114.045616], zoom_start=14)\n",
    "test_p = \"../data/taxi_after_proc/merged/12-11_粤BD99105.csv\"\n",
    "tracks = pd.read_csv(test_p)\n",
    "# 时间跨度不超过10分钟\n",
    "tracks['gps_time'] = pd.to_datetime(tracks['gps_time'])\n",
    "tmp = pd.Timedelta(minutes=10)\n",
    "cut = [0]\n",
    "for i in range(len(tracks) - 1):\n",
    "    if (tracks['gps_time'][i + 1] - tracks['gps_time'][i]) > tmp:\n",
    "        cut.append(i)\n",
    "\n",
    "# print(cut)\n",
    "\n",
    "for i in range(len(cut) - 1):\n",
    "    a = tracks.iloc[cut[i] + 1:cut[i + 1] + 1]\n",
    "    track_list = a[['lat', 'lng']].values.tolist()\n",
    "    if len(track_list) == 0:\n",
    "        continue\n",
    "    folium.PolyLine(track_list).add_to(m)\n",
    "    folium.Marker(track_list[0],popup='start',icon=folium.Icon(color='red')).add_to(m)\n",
    "    folium.Marker(track_list[-1],popup='end',icon=folium.Icon(color='green')).add_to(m)\n",
    "#     for n,posi in enumerate(track_list):\n",
    "#         if(n==0):\n",
    "#             continue\n",
    "#         if(n==len(track_list)-1):\n",
    "#             continue\n",
    "#         folium.Marker(posi).add_to(m)\n",
    "        \n",
    "\n",
    "folium.PolyLine(track_list).add_to(m)\n",
    "\n",
    "m.save(\"1.html\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe38619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一天轨迹的时间信息，\n",
    "test_p = \"../data/taxi_after_proc/merged/12-11_粤BD99105.csv\"\n",
    "tracks = pd.read_csv(test_p)\n",
    "t = tracks[\"gps_time\"].values.tolist()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b77904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取所有原始数据\n",
    "root_path = os.walk(\"../data/taxi\")\n",
    "all_files = []\n",
    "for root,ds,fs in root_path:\n",
    "    days = []\n",
    "    for f in fs:\n",
    "        full_path = os.path.join(root,f)\n",
    "        days.append(full_path)\n",
    "    if len(days)==0:\n",
    "        continue\n",
    "    all_files.append(days)\n",
    "all_files.sort()\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca69d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ['../data/taxi/2019-12-11/2019-12-11_5',\n",
    "  '../data/taxi/2019-12-11/2019-12-11_0',\n",
    "  '../data/taxi/2019-12-11/2019-12-11_2',\n",
    "  '../data/taxi/2019-12-11/2019-12-11_3',\n",
    "  '../data/taxi/2019-12-11/2019-12-11_1',\n",
    "  '../data/taxi/2019-12-11/2019-12-11_7',\n",
    "  '../data/taxi/2019-12-11/2019-12-11_8',\n",
    "  '../data/taxi/2019-12-11/2019-12-11_6',\n",
    "  '../data/taxi/2019-12-11/2019-12-11_4']\n",
    "path.sort()\n",
    "names=[\"sys_time\", \"license_number\", \"lng\", \"lat\", \"gps_time\", \"EMPTY1\", \"speed\", \"direction\", \"car_status\",\"alarm_status\",\n",
    "       \"EMPTY2\", \"EMPTY3\", \"license_color\", \"recorder_speed\", \"mileage\", \"height\", \"EMPTY4\"]\n",
    "\n",
    "\n",
    "records = []\n",
    "for each_time in tqdm(path):\n",
    "    records.append(pd.read_csv(each_time, names=names))\n",
    "#     records = records[(records[\"license_number\"]==\"粤BD99105\")]\n",
    "    \n",
    "#     print(records)\n",
    "#     break\n",
    "#     group = records.groupby(\"license_number\")\n",
    "#     for each_lincense, each_record in group:\n",
    "#         posi = each_record[['lat', 'lng', 'gps_time', 'speed', 'direction', 'car_status']]\n",
    "#         # 按gps时间排序，并去重\n",
    "#         posi['gps_time'] = pd.to_datetime(posi['gps_time'])\n",
    "#         posi.sort_values(by=\"gps_time\", inplace=True, ascending=True)\n",
    "#         posi = posi.drop_duplicates()\n",
    "#         # 去除错误日期的记录\n",
    "#         open_day = '2019-12-01'\n",
    "#         close_day = '2019-12-14'\n",
    "#         posi = posi[(posi['gps_time'] > open_day) & (posi['gps_time'] < close_day)]\n",
    "#         # 去除速度为0的记录\n",
    "#         posi = posi.loc[(posi != 0).all(axis=1)]\n",
    "#         # 去除数量过少的记录\n",
    "#         if len(posi) < 30:\n",
    "#             continue\n",
    "#         posi.to_csv(dest_path + each_time[-7:] + each_lincense + \".csv\", index=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2de470",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_records = []\n",
    "for each_record in tqdm(records):\n",
    "    each_record = each_record.drop(\"sys_time\",axis='columns')\n",
    "    car_record = each_record[(each_record[\"license_number\"]==\"粤BD99105\")]\n",
    "    car_record['gps_time'] = pd.to_datetime(car_record['gps_time'])\n",
    "    car_record.sort_values(by=\"gps_time\", inplace=True, ascending=True)\n",
    "    car_record = car_record.drop_duplicates()\n",
    "    car_record = car_record[(car_record[\"lat\"]!=0)]\n",
    "\n",
    "    car_records.append(car_record)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd36085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = folium.Map(location=[22.565050, 114.045616], zoom_start=14)\n",
    "# print(car_records[0])\n",
    "all_len = 0\n",
    "all_records = pd.DataFrame()\n",
    "for record in car_records:\n",
    "    print(record)\n",
    "    all_records = all_records.append(record)\n",
    "#     t = record[\"gps_time\"].tolist()\n",
    "all_records\n",
    "all_records.to_csv(\"粤BD99105_notprocess.csv\")\n",
    "#     all_len += len(t)\n",
    "\n",
    "# print(all_len)\n",
    "#     track_list = record[['lat', 'lng']].values.tolist()\n",
    "#     if len(track_list) == 0:\n",
    "#         continue\n",
    "#     folium.PolyLine(track_list).add_to(m)\n",
    "\n",
    "    \n",
    "# tracks['gps_time'] = pd.to_datetime(tracks['gps_time'])\n",
    "# tmp = pd.Timedelta(minutes=10)\n",
    "# cut = [0]\n",
    "# for i in range(len(tracks) - 1):\n",
    "#     if (tracks['gps_time'][i + 1] - tracks['gps_time'][i]) > tmp:\n",
    "#         cut.append(i)\n",
    "\n",
    "# for i in range(len(cut) - 1):\n",
    "#     a = tracks.iloc[cut[i] + 1:cut[i + 1] + 1]\n",
    "#     track_list = a[['lat', 'lng']].values.tolist()\n",
    "#     if len(track_list) == 0:\n",
    "#         continue\n",
    "#     folium.PolyLine(track_list).add_to(m)\n",
    "#     folium.Marker(track_list[0],popup='start',icon=folium.Icon(color='red')).add_to(m)\n",
    "#     folium.Marker(track_list[-1],popup='end',icon=folium.Icon(color='green')).add_to(m)\n",
    "\n",
    "# folium.PolyLine(track_list).add_to(m)\n",
    "\n",
    "# m.save(\"2.html\")\n",
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01a84191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names=[\"sys_time\", \"license_number\", \"lng\", \"lat\", \"gps_time\", \"EMPTY1\", \"speed\", \"direction\", \"car_status\",\"alarm_status\",\n",
    "#        \"EMPTY2\", \"EMPTY3\", \"license_color\", \"recorder_speed\", \"mileage\", \"height\", \"EMPTY4\"]\n",
    "\n",
    "# dest_path = \"../data/taxi_after_proc/proc_segment/\"\n",
    "# all_files.sort()\n",
    "# car_path = '../data/taxi/2019-12-02/2019-12-02_1'\n",
    "# car_path2 = '../data/taxi/2019-12-02/2019-12-02_2'\n",
    "\n",
    "# df = []\n",
    "# records1 = pd.read_csv(car_path,names = names)\n",
    "# records2 = pd.read_csv(car_path2,names = names)\n",
    "# df.append(records1)\n",
    "# df.append(records2)\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff67f61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# posi = records2[['license_number','lat', 'lng', 'gps_time', 'speed', 'direction', 'car_status']]\n",
    "# print(len(posi))\n",
    "# # 按gps时间排序，并去重\n",
    "# posi['gps_time'] = pd.to_datetime(posi['gps_time'])\n",
    "# posi.sort_values(by=\"gps_time\", inplace=True, ascending=True)\n",
    "# posi = posi.drop_duplicates()\n",
    "# print(len(posi))\n",
    "\n",
    "# # 去除错误日期的记录\n",
    "# open_day = '2019-12-01'\n",
    "# close_day = '2019-12-03'\n",
    "# posi = posi[(posi['gps_time'] > open_day) & (posi['gps_time'] < close_day)]\n",
    "# print(len(posi))\n",
    "# print(posi.head(30))\n",
    "\n",
    "# # 去除速度为0的记录\n",
    "# posi = posi.loc[(posi != 0).all(axis=1)]\n",
    "# print(len(posi))\n",
    "\n",
    "# # 去除数量过少的记录\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "622e99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names=[\"sys_time\", \"license_number\", \"lng\", \"lat\", \"gps_time\", \"EMPTY1\", \"speed\", \"direction\", \"car_status\",\"alarm_status\",\n",
    "#        \"EMPTY2\", \"EMPTY3\", \"license_color\", \"recorder_speed\", \"mileage\", \"height\", \"EMPTY4\"]\n",
    "\n",
    "# car_path = [\n",
    "# \"../data/taxi/2019-12-02/2019-12-02_0\",\n",
    "# \"../data/taxi/2019-12-02/2019-12-02_1\",\n",
    "# \"../data/taxi/2019-12-02/2019-12-02_2\",\n",
    "# \"../data/taxi/2019-12-02/2019-12-02_3\",\n",
    "# \"../data/taxi/2019-12-02/2019-12-02_4\",\n",
    "# \"../data/taxi/2019-12-02/2019-12-02_5\",\n",
    "# \"../data/taxi/2019-12-02/2019-12-02_6\",\n",
    "# \"../data/taxi/2019-12-02/2019-12-02_7\"\n",
    "# ]\n",
    "# df = []\n",
    "# records = []\n",
    "# for p in car_path:\n",
    "#     records.append(pd.read_csv(p,names = names,nrows=20000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58240ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for records1 in records:\n",
    "#     posi = records1[['license_number',  'gps_time', 'speed', 'direction', 'car_status']]\n",
    "#     # 按gps时间排序，并去重\n",
    "#     posi['gps_time'] = pd.to_datetime(posi['gps_time'])\n",
    "#     posi.sort_values(by=\"gps_time\", inplace=True, ascending=True)\n",
    "#     posi = posi.drop_duplicates()\n",
    "\n",
    "#     # 去除错误日期的记录\n",
    "#     open_day = '2019-12-01'\n",
    "#     close_day = '2019-12-03'\n",
    "#     posi = posi[(posi['gps_time'] > open_day) & (posi['gps_time'] < close_day)]\n",
    "\n",
    "#     # 去除速度为0的记录\n",
    "#     posi = posi.loc[(posi != 0).all(axis=1)]\n",
    "# #     print(posi.head(3))\n",
    "    \n",
    "# #     print(len(posi))\n",
    "#     speed_avg = posi['speed'].mean()\n",
    "#     print(speed_avg)\n",
    "# #     print()\n",
    "\n",
    "#     # 去除数量过少的记录\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c527a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# car = [\n",
    "# \"../data/taxi_after_proc/proc_segment/12-02_0粤BD01819.csv\",\n",
    "# \"../data/taxi_after_proc/proc_segment/12-02_1粤BD01819.csv\",\n",
    "# \"../data/taxi_after_proc/proc_segment/12-02_2粤BD01819.csv\",\n",
    "# \"../data/taxi_after_proc/proc_segment/12-02_3粤BD01819.csv\",\n",
    "# \"../data/taxi_after_proc/proc_segment/12-02_4粤BD01819.csv\",\n",
    "# \"../data/taxi_after_proc/proc_segment/12-02_5粤BD01819.csv\",\n",
    "# \"../data/taxi_after_proc/proc_segment/12-02_6粤BD01819.csv\",\n",
    "# \"../data/taxi_after_proc/proc_segment/12-02_7粤BD01819.csv\"\n",
    "# ]\n",
    "# for each_time in car:\n",
    "#     car_tmp = pd.read_csv(each_time)\n",
    "# #     print(len(car_tmp))\n",
    "#     print(car_tmp.head(10))\n",
    "#     print(car_tmp['speed'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36e53741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for records1 in records:\n",
    "#     posi = records1[['license_number',  'gps_time', 'speed', 'direction', 'car_status']]\n",
    "#     # 按gps时间排序，并去重\n",
    "#     posi['gps_time'] = pd.to_datetime(posi['gps_time'])\n",
    "#     posi.sort_values(by=\"gps_time\", inplace=True, ascending=True)\n",
    "#     posi = posi.drop_duplicates()\n",
    "\n",
    "#     # 去除错误日期的记录\n",
    "#     open_day = '2019-12-01'\n",
    "#     close_day = '2019-12-03'\n",
    "#     posi = posi[(posi['gps_time'] > open_day) & (posi['gps_time'] < close_day)]\n",
    "\n",
    "#     # 去除速度为0的记录\n",
    "# #     posi = posi.loc[(posi != 0).all(axis=1)]\n",
    "# #     print(posi.head(3))\n",
    "# #     print(len(posi))\n",
    "#     speed_list = posi['speed'].values.tolist()\n",
    "#     plt.figure()\n",
    "#     freq, bins, _ = plt.hist(speed_list, rwidth=0.8) # 参数 ，下限大一些，\n",
    "#     plt.title('Velocity statistical analysis')\n",
    "#     plt.xlabel('speed (km/h)')\n",
    "#     plt.ylabel('amount of different speed')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd0b5aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for records1 in records:\n",
    "#     posi = records1[['license_number',  'gps_time', 'speed', 'direction', 'car_status']]\n",
    "#     # 按gps时间排序，并去重\n",
    "#     posi['gps_time'] = pd.to_datetime(posi['gps_time'])\n",
    "#     posi.sort_values(by=\"gps_time\", inplace=True, ascending=True)\n",
    "#     posi = posi.drop_duplicates()\n",
    "\n",
    "#     # 去除错误日期的记录\n",
    "#     open_day = '2019-12-01'\n",
    "#     close_day = '2019-12-03'\n",
    "#     posi = posi[(posi['gps_time'] > open_day) & (posi['gps_time'] < close_day)]\n",
    "\n",
    "#     # 去除速度为0的记录\n",
    "# #     posi = posi.loc[(posi != 0).all(axis=1)]\n",
    "#     posi = posi[(posi['speed']>0)&(posi['speed']<150)]\n",
    "# #     print(posi.head(3))\n",
    "# #     print(len(posi))\n",
    "#     speed_cnt = posi['speed'].value_counts()\n",
    "    \n",
    "#     print(type(speed_cnt))\n",
    "#     d = speed_cnt.to_dict()\n",
    "#     d_list = sorted(list(d.items()),key=lambda x:x[0])\n",
    "#     print(d_list)\n",
    "#     y_max = d_list[-1][0]+1\n",
    "#     y = list(range(y_max))\n",
    "#     x = []\n",
    "#     print(d[2])\n",
    "#     for i in range(y_max):\n",
    "#         if i in d:\n",
    "#             x.append(d[i])\n",
    "#         else:\n",
    "#             x.append(0)\n",
    "#     print(y)\n",
    "#     print(x)\n",
    "# #     y_max = \n",
    "#     plt.figure()\n",
    "#     plt.plot(y,x)\n",
    "#     plt.title('Velocity statistical analysis')\n",
    "#     plt.xlabel('speed (km/h)')\n",
    "#     plt.ylabel('amount of different speed')\n",
    "#     plt.show()\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a78d2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ca19f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for records1 in records:\n",
    "#     posi = records1[['license_number',  'gps_time', 'speed']]\n",
    "#     # 按gps时间排序，并去重\n",
    "#     posi['gps_time'] = pd.to_datetime(posi['gps_time'])\n",
    "#     posi.sort_values(by=\"gps_time\", inplace=True, ascending=True)\n",
    "#     posi = posi.drop_duplicates()\n",
    "\n",
    "#     # 去除错误日期的记录\n",
    "#     open_day = '2019-12-01'\n",
    "#     close_day = '2019-12-03'\n",
    "#     posi = posi[(posi['gps_time'] > open_day) & (posi['gps_time'] < close_day)]\n",
    "\n",
    "#     # 去除速度为0的记录\n",
    "# #     posi = posi.loc[(posi != 0).all(axis=1)]\n",
    "# #     posi = posi[(posi['speed']>0)&(posi['speed']<150)]\n",
    "\n",
    "# #     speed_list = posi['speed'].values.tolist()\n",
    "#     speed_cnt = posi['speed'].value_counts()\n",
    "    \n",
    "#     print(type(speed_cnt))\n",
    "#     d = speed_cnt.to_dict()\n",
    "#     d_list = sorted(list(d.items()),key=lambda x:x[0])\n",
    "#     print(d_list)\n",
    "#     y_max = d_list[-1][0]+1\n",
    "#     y = list(range(y_max))\n",
    "#     x = []\n",
    "#     print(d[2])\n",
    "#     for i in range(y_max):\n",
    "#         if i in d:\n",
    "#             x.append(d[i])\n",
    "#         else:\n",
    "#             x.append(0)\n",
    "#     print(y)\n",
    "#     print(x)\n",
    "# #     y_max = \n",
    "#     plt.figure()\n",
    "#     plt.plot(y,x)\n",
    "#     plt.title('Velocity statistical analysis')\n",
    "#     plt.xlabel('speed (km/h)')\n",
    "#     plt.ylabel('amount of different speed')\n",
    "#     plt.show()\n",
    "    \n",
    "#     break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b038b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.dates as dates\n",
    "\n",
    "# car = [\n",
    "# \"../data/taxi_after_proc/proc_segment/12-02_0粤BD01819.csv\",\n",
    "# \"../data/taxi_after_proc/proc_segment/12-02_1粤BD01819.csv\",\n",
    "# \"../data/taxi_after_proc/proc_segment/12-02_2粤BD01819.csv\",\n",
    "# \"../data/taxi_after_proc/proc_segment/12-02_3粤BD01819.csv\",\n",
    "# \"../data/taxi_after_proc/proc_segment/12-02_4粤BD01819.csv\",\n",
    "# \"../data/taxi_after_proc/proc_segment/12-02_5粤BD01819.csv\",\n",
    "# \"../data/taxi_after_proc/proc_segment/12-02_6粤BD01819.csv\",\n",
    "# \"../data/taxi_after_proc/proc_segment/12-02_7粤BD01819.csv\"\n",
    "# ]\n",
    "# x = []\n",
    "# y = []\n",
    "# for each_time in car:\n",
    "#     tracks = pd.read_csv(each_time)\n",
    "# #     print(len(car_tmp))\n",
    "#     # 时间跨度不超过10分钟\n",
    "#     tracks['gps_time'] = pd.to_datetime(tracks['gps_time'])\n",
    "#     x.append(tracks['gps_time'].values.tolist())\n",
    "#     y.append(tracks['speed'].values.tolist())\n",
    "#     break\n",
    "#     # tracks['gps_time'] = tracks\n",
    "#     # print(tracks)\n",
    "#     # print(tracks.iloc[0:3])\n",
    "    \n",
    "# xfmt = mdates.DateFormatter('%y-%m-%d %H:%M')\n",
    "# ax.xaxis.set_major_formatter(xfmt)\n",
    "\n",
    "# plt.plot(x,y)\n",
    "# plt.show()\n",
    "# print(x)\n",
    "# print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dz] *",
   "language": "python",
   "name": "conda-env-dz-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
